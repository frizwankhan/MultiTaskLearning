
Epoch 0, Loss: 30.1064, step: 0:   0%|                                                                                 | 0/125 [00:05<?, ?it/s]
  0%|                                                                                                                  | 0/160 [00:00<?, ?it/s]














 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                           | 20/160 [00:34<03:23,  1.45s/it]
 Edge Detection Evaluation
Edge Detection Loss 0.054
Human Parts mIoU: 2.4857
background     14.4399
head           0.0000
torso          0.0000
uarm           1.7523
larm           0.0000
uleg           0.0000
lleg           1.2076
Semantic Segmentation mIoU: 0.0483
background          0.0000
aeroplane           0.0000
bicycle             0.0000
bird                0.0624
boat                0.0000
bottle              0.0003
bus                 0.0000
car                 0.0000
cat                 0.0000
chair               0.0000
cow                 0.7192
diningtable         0.0237
dog                 0.0000
horse               0.0000
motorbike           0.0000
person              0.0000
pottedplant         0.0000
sheep               0.2080
sofa                0.0000
train               0.0000
tvmonitor           0.0004
Validation Done


















































Epoch 0, Loss: 28.8385, step: 99:   0%|                                                                                | 0/125 [02:41<?, ?it/s]
Epoch 0, Loss: 29.6090, step: 100:   0%|                                                                               | 0/125 [02:42<?, ?it/s]














 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                           | 20/160 [00:36<03:41,  1.58s/it]
 Edge Detection Evaluation
Edge Detection Loss 0.054
Human Parts mIoU: 3.2751
background     20.0704
head           0.0000
torso          0.0000
uarm           1.5213
larm           0.0000
uleg           0.0000
lleg           1.3340
Semantic Segmentation mIoU: 0.0562
background          0.0000
aeroplane           0.0000
bicycle             0.0000
bird                0.1156
boat                0.0000
bottle              0.0001
bus                 0.0000
car                 0.0000
cat                 0.0003
chair               0.0000
cow                 0.5639
diningtable         0.0299
dog                 0.0000
horse               0.0000
motorbike           0.0000
person              0.0000
pottedplant         0.0000
sheep               0.4695
sofa                0.0000
train               0.0000
tvmonitor           0.0003
Validation Done












Epoch 0, Loss: 28.8461, step: 124:   0%|                                                                               | 0/125 [03:48<?, ?it/s]
  0%|                                                                                                                  | 0/125 [00:00<?, ?it/s]




[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 124. Dropping entry: {'epoch_loss_train': 29.016477554321288, '_timestamp': 1711022011.23648}).































Epoch 1, Loss: 27.7212, step: 74:   0%|                                                                                | 0/125 [01:20<?, ?it/s]

Epoch 1, Loss: 27.3305, step: 75:   0%|                                                                                | 0/125 [01:21<?, ?it/s]
 Edge Detection Evaluation
Edge Detection Loss 0.054
Human Parts mIoU: 6.3700
background     41.9359
head           0.0000
torso          0.0000
uarm           1.3012
larm           0.0000
uleg           0.0000
lleg           1.3527
Semantic Segmentation mIoU: 0.0595
background          0.0000
aeroplane           0.0000
bicycle             0.0000
bird                0.2902
boat                0.0000
bottle              0.0003
bus                 0.0000
car                 0.0000
cat                 0.0000
chair               0.0000
cow                 0.4117
diningtable         0.0006
dog                 0.0000
horse               0.0000
motorbike           0.0000
person              0.0000
pottedplant         0.0000
sheep               0.5474
sofa                0.0000
train               0.0000
tvmonitor           0.0000
Validation Done
Epoch: 1| Iteration: 200| TrainingLoss: 27.33045196533203| ValidationLoss: 3.613678503036499








  File "main.py", line 59, in <module>|                                                                                | 0/125 [02:18<?, ?it/s]
    trainer.train(config)
  File "/raid/home/rizwank/courses/DLCV/Project/train.py", line 107, in train
    loss, loss_dict = self.train_step(batch)
  File "/raid/home/rizwank/courses/DLCV/Project/train.py", line 40, in train_step
    output = self.model.module(images)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/model.py", line 189, in forward
    x = self.swin_encoder_decoder(x)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/model.py", line 121, in forward
    decoder_out, _ = self.task_decoder[task_id][i](decoder_inp)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/model.py", line 32, in forward
    out = self.model(x, output_hidden_states=True)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 1012, in forward
    encoder_outputs = self.encoder(
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 837, in forward
    layer_outputs = layer_module(
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 757, in forward
    layer_outputs = layer_module(
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 684, in forward
    attn_mask = self.get_attn_mask(height_pad, width_pad, dtype=hidden_states.dtype)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 638, in get_attn_mask
    attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)
KeyboardInterrupt