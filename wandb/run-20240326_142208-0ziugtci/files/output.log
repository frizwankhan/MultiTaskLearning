
  0%|                                                                                                                                                                              | 0/248 [00:00<?, ?it/s]
memory occupied before training 1.5264334678649902
memory occupied before train_setp 1.5264334678649902
memory occupied after train_setp 1.6440391540527344
torch.Size([10952, 3, 49, 32]) torch.Size([10952, 3, 49, 32])
torch.Size([10952, 3, 49, 32]) torch.Size([10952, 3, 49, 32])
torch.Size([2812, 6, 49, 32]) torch.Size([2812, 6, 49, 32])
torch.Size([2812, 6, 49, 32]) torch.Size([2812, 6, 49, 32])
torch.Size([760, 12, 49, 32]) torch.Size([760, 12, 49, 32])
torch.Size([760, 12, 49, 32]) torch.Size([760, 12, 49, 32])
torch.Size([760, 12, 49, 32]) torch.Size([760, 12, 49, 32])
torch.Size([760, 12, 49, 32]) torch.Size([760, 12, 49, 32])
torch.Size([760, 12, 49, 32]) torch.Size([760, 12, 49, 32])
torch.Size([760, 12, 49, 32]) torch.Size([760, 12, 49, 32])
torch.Size([200, 24, 49, 32]) torch.Size([200, 24, 49, 32])
torch.Size([200, 24, 49, 32]) torch.Size([200, 24, 49, 32])
torch.Size([128, 48, 16, 32]) torch.Size([128, 48, 16, 32])
torch.Size([128, 48, 16, 32]) torch.Size([128, 48, 16, 32])
torch.Size([512, 24, 16, 32]) torch.Size([512, 24, 16, 32])
torch.Size([512, 24, 16, 32]) torch.Size([512, 24, 16, 32])
torch.Size([512, 12, 64, 32]) torch.Size([512, 12, 64, 32])
torch.Size([512, 12, 64, 32]) torch.Size([512, 12, 64, 32])
torch.Size([2048, 6, 64, 32]) torch.Size([2048, 6, 64, 32])
torch.Size([2048, 6, 64, 32]) torch.Size([2048, 6, 64, 32])
torch.Size([128, 48, 16, 32]) torch.Size([128, 48, 16, 32])
torch.Size([128, 48, 16, 32]) torch.Size([128, 48, 16, 32])
torch.Size([512, 24, 16, 32]) torch.Size([512, 24, 16, 32])
torch.Size([512, 24, 16, 32]) torch.Size([512, 24, 16, 32])
torch.Size([512, 12, 64, 32]) torch.Size([512, 12, 64, 32])
torch.Size([512, 12, 64, 32]) torch.Size([512, 12, 64, 32])
  0%|                                                                                                                                                                              | 0/248 [00:00<?, ?it/s]Traceback (most recent call last):
  File "main.py", line 68, in <module>
    trainer.train(config)
  File "/raid/home/rizwank/courses/DLCV/Project/train.py", line 115, in train
    loss, loss_dict = self.train_step(batch)
  File "/raid/home/rizwank/courses/DLCV/Project/train.py", line 44, in train_step
    output = self.model.module(images)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/model.py", line 206, in forward
    x = self.swin_encoder_decoder(x)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/model.py", line 120, in forward
    decoder_out, _ = self.task_decoder[task_id][i](decoder_inp)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/model.py", line 31, in forward
    out = self.model(x, output_hidden_states=True)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 1012, in forward
    encoder_outputs = self.encoder(
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 837, in forward
    layer_outputs = layer_module(
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 757, in forward
    layer_outputs = layer_module(
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 688, in forward
    attention_outputs = self.attention(
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 563, in forward
    self_outputs = self.self(hidden_states, attention_mask, head_mask, output_attentions)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 476, in forward
    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 63.38 MiB is free. Process 2991625 has 436.00 MiB memory in use. Including non-PyTorch memory, this process has 31.24 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 637.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)