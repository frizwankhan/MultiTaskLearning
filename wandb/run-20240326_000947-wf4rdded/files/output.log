
Epoch 0, Loss: 329.0665, step: 0:   0%|                                                                                                                                            | 0/496 [00:03<?, ?it/s]
  0%|                                                                                                                                                             | 0/250 [00:00<?, ?it/s]

















































































100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [02:41<00:00,  1.69it/s]
Results for depth prediction
rmse           38.0546
log_rmse       13.9651
abs_rel        0.9952
sq_rel         30.6480
Semantic Segmentation mIoU: 1.0246
background          5.7305
aeroplane           4.4855
bicycle             0.0713
bird                0.2840
boat                0.7888
bottle              0.5076
bus                 0.2256
car                 0.4580
cat                 1.9871
chair               0.1475
cow                 0.9576
diningtable         1.2977
dog                 0.2188
horse               3.2144
motorbike           0.2531
person              0.3174
pottedplant         0.0498
sheep               0.0235
sofa                0.4977
train               0.0000
tvmonitor           0.0000

Epoch 0, Loss: 334.7418, step: 1:   0%|                                                                                                                                            | 0/496 [02:50<?, ?it/s]
























































































Epoch 0, Loss: 288.8861, step: 199:   0%|                                                                                                                                          | 0/496 [05:48<?, ?it/s]Traceback (most recent call last):
  File "main.py", line 64, in <module>
    trainer.train(config)
  File "/raid/home/rizwank/courses/DLCV/Project/train.py", line 109, in train
    loss, loss_dict = self.train_step(batch)
  File "/raid/home/rizwank/courses/DLCV/Project/train.py", line 40, in train_step
    output = self.model.module(images)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/model.py", line 206, in forward
    x = self.swin_encoder_decoder(x)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/model.py", line 101, in forward
    out, out_downsampled = self.encoder(x) #out_downsampled=(batch_size, h/64*w/64, 1536)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/model.py", line 31, in forward
    out = self.model(x, output_hidden_states=True)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 1012, in forward
    encoder_outputs = self.encoder(
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 837, in forward
    layer_outputs = layer_module(
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 757, in forward
    layer_outputs = layer_module(
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 684, in forward
    attn_mask = self.get_attn_mask(height_pad, width_pad, dtype=hidden_states.dtype)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 639, in get_attn_mask
    attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))
KeyboardInterrupt