
  0%|                                                                                                                                                             | 0/248 [00:00<?, ?it/s]
memory occupied before training 1.5308036804199219
memory occupied before train_setp 1.5308036804199219
memory occupied after train_setp 1.6479911804199219
memory occupied  18.680959701538086
memory occupied  0.0
memory occupied  0.0
memory occupied  19.10295009613037
memory occupied  0.0
memory occupied  0.0
decoder out 12.0 torch.Size([4, 512, 1536]) 4
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  19549 MiB |  19609 MiB |  40029 MiB |  20480 MiB |
|       from large pool |  19503 MiB |  19563 MiB |  39895 MiB |  20391 MiB |
|       from small pool |     45 MiB |     46 MiB |    133 MiB |     88 MiB |
|---------------------------------------------------------------------------|
| Active memory         |  19549 MiB |  19609 MiB |  40029 MiB |  20480 MiB |
|       from large pool |  19503 MiB |  19563 MiB |  39895 MiB |  20391 MiB |
|       from small pool |     45 MiB |     46 MiB |    133 MiB |     88 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |  19530 MiB |  19590 MiB |  39999 MiB |  20469 MiB |
|       from large pool |  19484 MiB |  19544 MiB |  39865 MiB |  20380 MiB |
|       from small pool |     45 MiB |     46 MiB |    133 MiB |     88 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  19890 MiB |  19916 MiB |  19916 MiB |  26624 KiB |
|       from large pool |  19844 MiB |  19868 MiB |  19868 MiB |  24576 KiB |
|       from small pool |     46 MiB |     48 MiB |     48 MiB |   2048 KiB |
|---------------------------------------------------------------------------|
| Non-releasable memory | 348793 KiB | 743586 KiB |   8031 MiB |   7690 MiB |
|       from large pool | 348240 KiB | 741256 KiB |   7905 MiB |   7565 MiB |
|       from small pool |    553 KiB |   4577 KiB |    126 MiB |    125 MiB |
|---------------------------------------------------------------------------|
| Allocations           |     878    |     884    |    1276    |     398    |
|       from large pool |     302    |     307    |     559    |     257    |
|       from small pool |     576    |     579    |     717    |     141    |
|---------------------------------------------------------------------------|
| Active allocs         |     878    |     884    |    1276    |     398    |
|       from large pool |     302    |     307    |     559    |     257    |
|       from small pool |     576    |     579    |     717    |     141    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     214    |     214    |       3    |
|       from large pool |     188    |     190    |     190    |       2    |
|       from small pool |      23    |      24    |      24    |       1    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     104    |     109    |     384    |     280    |
|       from large pool |      99    |     105    |     274    |     175    |
|       from small pool |       5    |      12    |     110    |     105    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
memory occupied  19.091193199157715
memory occupied  0.0
memory occupied  0.0
memory occupied  19.161505699157715
memory occupied  0.0
memory occupied  0.0
memory occupied  19.982196807861328
memory occupied  0.0
memory occupied  0.0
decoder out 24.0 torch.Size([4, 2048, 768]) 4
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  20437 MiB |  20581 MiB |  41806 MiB |  21368 MiB |
|       from large pool |  20391 MiB |  20535 MiB |  41659 MiB |  21267 MiB |
|       from small pool |     45 MiB |     46 MiB |    146 MiB |    100 MiB |
|---------------------------------------------------------------------------|
| Active memory         |  20437 MiB |  20581 MiB |  41806 MiB |  21368 MiB |
|       from large pool |  20391 MiB |  20535 MiB |  41659 MiB |  21267 MiB |
|       from small pool |     45 MiB |     46 MiB |    146 MiB |    100 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |  20418 MiB |  20562 MiB |  41775 MiB |  21357 MiB |
|       from large pool |  20372 MiB |  20516 MiB |  41629 MiB |  21256 MiB |
|       from small pool |     45 MiB |     46 MiB |    146 MiB |    100 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  20762 MiB |  20956 MiB |  20982 MiB | 225280 KiB |
|       from large pool |  20716 MiB |  20908 MiB |  20932 MiB | 221184 KiB |
|       from small pool |     46 MiB |     48 MiB |     50 MiB |   4096 KiB |
|---------------------------------------------------------------------------|
| Non-releasable memory | 332088 KiB | 743586 KiB |   8155 MiB |   7831 MiB |
|       from large pool | 331856 KiB | 741256 KiB |   8017 MiB |   7693 MiB |
|       from small pool |    232 KiB |   4577 KiB |    138 MiB |    138 MiB |
|---------------------------------------------------------------------------|
| Allocations           |     915    |     922    |    1374    |     459    |
|       from large pool |     327    |     333    |     622    |     295    |
|       from small pool |     588    |     592    |     752    |     164    |
|---------------------------------------------------------------------------|
| Active allocs         |     915    |     922    |    1374    |     459    |
|       from large pool |     327    |     333    |     622    |     295    |
|       from small pool |     588    |     592    |     752    |     164    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     234    |     242    |     245    |      11    |
|       from large pool |     211    |     218    |     220    |       9    |
|       from small pool |      23    |      24    |      25    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     104    |     109    |     405    |     301    |
|       from large pool |     100    |     105    |     276    |     176    |
|       from small pool |       4    |      12    |     129    |     125    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
memory occupied  19.95868682861328
memory occupied  0.0
memory occupied  0.0
memory occupied  20.09931182861328
memory occupied  0.0
memory occupied  0.0
memory occupied  21.882033348083496
memory occupied  0.0
memory occupied  0.0
decoder out 48.0 torch.Size([4, 8192, 384]) 4
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  22358 MiB |  22648 MiB |  45924 MiB |  23565 MiB |
|       from large pool |  22311 MiB |  22601 MiB |  45763 MiB |  23451 MiB |
|       from small pool |     47 MiB |     48 MiB |    160 MiB |    113 MiB |
|---------------------------------------------------------------------------|
| Active memory         |  22358 MiB |  22648 MiB |  45924 MiB |  23565 MiB |
|       from large pool |  22311 MiB |  22601 MiB |  45763 MiB |  23451 MiB |
|       from small pool |     47 MiB |     48 MiB |    160 MiB |    113 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |  22339 MiB |  22629 MiB |  45893 MiB |  23553 MiB |
|       from large pool |  22292 MiB |  22582 MiB |  45732 MiB |  23440 MiB |
|       from small pool |     46 MiB |     47 MiB |    160 MiB |    113 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  22714 MiB |  23086 MiB |  23306 MiB | 606208 KiB |
|       from large pool |  22666 MiB |  23036 MiB |  23252 MiB | 600064 KiB |
|       from small pool |     48 MiB |     50 MiB |     54 MiB |   6144 KiB |
|---------------------------------------------------------------------------|
| Non-releasable memory | 363575 KiB | 743586 KiB |   8455 MiB |   8100 MiB |
|       from large pool | 362576 KiB | 741256 KiB |   8301 MiB |   7947 MiB |
|       from small pool |    999 KiB |   4577 KiB |    153 MiB |    152 MiB |
|---------------------------------------------------------------------------|
| Allocations           |     952    |     959    |    1473    |     521    |
|       from large pool |     352    |     359    |     687    |     335    |
|       from small pool |     600    |     604    |     786    |     186    |
|---------------------------------------------------------------------------|
| Active allocs         |     952    |     959    |    1473    |     521    |
|       from large pool |     352    |     359    |     687    |     335    |
|       from small pool |     600    |     604    |     786    |     186    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     258    |     266    |     277    |      19    |
|       from large pool |     234    |     241    |     250    |      16    |
|       from small pool |      24    |      25    |      27    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     105    |     109    |     425    |     320    |
|       from large pool |     101    |     105    |     287    |     186    |
|       from small pool |       4    |      12    |     138    |     134    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
memory occupied  21.834908485412598
memory occupied  0.0
memory occupied  0.0
memory occupied  22.116158485412598
memory occupied  0.0
memory occupied  0.0
memory occupied  25.684521675109863
memory occupied  0.0
memory occupied  0.0
decoder out 96.0 torch.Size([4, 32768, 192]) 4
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  26203 MiB |  26787 MiB |  54178 MiB |  27974 MiB |
|       from large pool |  26151 MiB |  26735 MiB |  53999 MiB |  27847 MiB |
|       from small pool |     52 MiB |     53 MiB |    179 MiB |    127 MiB |
|---------------------------------------------------------------------------|
| Active memory         |  26203 MiB |  26787 MiB |  54178 MiB |  27974 MiB |
|       from large pool |  26151 MiB |  26735 MiB |  53999 MiB |  27847 MiB |
|       from small pool |     52 MiB |     53 MiB |    179 MiB |    127 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |  26184 MiB |  26768 MiB |  54146 MiB |  27961 MiB |
|       from large pool |  26132 MiB |  26716 MiB |  53967 MiB |  27834 MiB |
|       from small pool |     51 MiB |     52 MiB |    179 MiB |    127 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  26642 MiB |  27218 MiB |  27810 MiB |   1168 MiB |
|       from large pool |  26588 MiB |  27164 MiB |  27750 MiB |   1162 MiB |
|       from small pool |     54 MiB |     54 MiB |     60 MiB |      6 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory | 448566 KiB | 743586 KiB |   9060 MiB |   8622 MiB |
|       from large pool | 446544 KiB | 741256 KiB |   8888 MiB |   8452 MiB |
|       from small pool |   2022 KiB |   4577 KiB |    171 MiB |    169 MiB |
|---------------------------------------------------------------------------|
| Allocations           |     989    |     996    |    1572    |     583    |
|       from large pool |     377    |     384    |     752    |     375    |
|       from small pool |     612    |     616    |     820    |     208    |
|---------------------------------------------------------------------------|
| Active allocs         |     989    |     996    |    1572    |     583    |
|       from large pool |     377    |     384    |     752    |     375    |
|       from small pool |     612    |     616    |     820    |     208    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     284    |     290    |     309    |      25    |
|       from large pool |     257    |     263    |     279    |      22    |
|       from small pool |      27    |      27    |      30    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     108    |     109    |     452    |     344    |
|       from large pool |     103    |     105    |     297    |     194    |
|       from small pool |       5    |      12    |     155    |     150    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
memory occupied  25.589792251586914
memory occupied  0.0
memory occupied  0.0
memory occupied  25.777292251586914
memory occupied  0.0
memory occupied  0.0
memory occupied  26.1992826461792
memory occupied  0.0
memory occupied  0.0
decoder out 12.0 torch.Size([4, 512, 1536]) 4
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  26816 MiB |  26876 MiB |  55457 MiB |  28641 MiB |
|       from large pool |  26763 MiB |  26823 MiB |  55265 MiB |  28501 MiB |
|       from small pool |     52 MiB |     53 MiB |    191 MiB |    139 MiB |
|---------------------------------------------------------------------------|
| Active memory         |  26816 MiB |  26876 MiB |  55457 MiB |  28641 MiB |
|       from large pool |  26763 MiB |  26823 MiB |  55265 MiB |  28501 MiB |
|       from small pool |     52 MiB |     53 MiB |    191 MiB |    139 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |  26796 MiB |  26856 MiB |  55425 MiB |  28628 MiB |
|       from large pool |  26744 MiB |  26804 MiB |  55233 MiB |  28488 MiB |
|       from small pool |     52 MiB |     53 MiB |    191 MiB |    139 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  27184 MiB |  27218 MiB |  28364 MiB |   1180 MiB |
|       from large pool |  27130 MiB |  27164 MiB |  28304 MiB |   1174 MiB |
|       from small pool |     54 MiB |     54 MiB |     60 MiB |      6 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory | 376805 KiB | 743586 KiB |   9706 MiB |   9338 MiB |
|       from large pool | 374864 KiB | 741256 KiB |   9522 MiB |   9156 MiB |
|       from small pool |   1941 KiB |   4577 KiB |    183 MiB |    181 MiB |
|---------------------------------------------------------------------------|
| Allocations           |    1026    |    1032    |    1667    |     641    |
|       from large pool |     402    |     407    |     812    |     410    |
|       from small pool |     624    |     627    |     855    |     231    |
|---------------------------------------------------------------------------|
| Active allocs         |    1026    |    1032    |    1667    |     641    |
|       from large pool |     402    |     407    |     812    |     410    |
|       from small pool |     624    |     627    |     855    |     231    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     288    |     290    |     314    |      26    |
|       from large pool |     261    |     263    |     284    |      23    |
|       from small pool |      27    |      27    |      30    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     109    |     110    |     484    |     375    |
|       from large pool |     104    |     106    |     324    |     220    |
|       from small pool |       5    |      12    |     160    |     155    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
memory occupied  26.187525749206543
memory occupied  0.0
memory occupied  0.0
memory occupied  26.257838249206543
memory occupied  0.0
memory occupied  0.0
memory occupied  27.078529357910156
memory occupied  0.0
memory occupied  0.0
decoder out 24.0 torch.Size([4, 2048, 768]) 4
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  27704 MiB |  27848 MiB |  57233 MiB |  29529 MiB |
|       from large pool |  27651 MiB |  27795 MiB |  57029 MiB |  29377 MiB |
|       from small pool |     52 MiB |     53 MiB |    204 MiB |    152 MiB |
|---------------------------------------------------------------------------|
| Active memory         |  27704 MiB |  27848 MiB |  57233 MiB |  29529 MiB |
|       from large pool |  27651 MiB |  27795 MiB |  57029 MiB |  29377 MiB |
|       from small pool |     52 MiB |     53 MiB |    204 MiB |    152 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |  27685 MiB |  27829 MiB |  57201 MiB |  29516 MiB |
|       from large pool |  27632 MiB |  27776 MiB |  56997 MiB |  29364 MiB |
|       from small pool |     52 MiB |     53 MiB |    204 MiB |    152 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  28056 MiB |  28242 MiB |  29422 MiB |   1366 MiB |
|       from large pool |  28002 MiB |  28188 MiB |  29362 MiB |   1360 MiB |
|       from small pool |     54 MiB |     54 MiB |     60 MiB |      6 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory | 360100 KiB | 743586 KiB |   9824 MiB |   9472 MiB |
|       from large pool | 358480 KiB | 741256 KiB |   9628 MiB |   9278 MiB |
|       from small pool |   1620 KiB |   4577 KiB |    195 MiB |    194 MiB |
|---------------------------------------------------------------------------|
| Allocations           |    1063    |    1070    |    1765    |     702    |
|       from large pool |     427    |     433    |     875    |     448    |
|       from small pool |     636    |     640    |     890    |     254    |
|---------------------------------------------------------------------------|
| Active allocs         |    1063    |    1070    |    1765    |     702    |
|       from large pool |     427    |     433    |     875    |     448    |
|       from small pool |     636    |     640    |     890    |     254    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     311    |     318    |     344    |      33    |
|       from large pool |     284    |     291    |     314    |      30    |
|       from small pool |      27    |      27    |      30    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     107    |     110    |     499    |     392    |
|       from large pool |     103    |     106    |     333    |     230    |
|       from small pool |       4    |      12    |     166    |     162    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
memory occupied  27.05501937866211
memory occupied  0.0
memory occupied  0.0
memory occupied  27.19564437866211
memory occupied  0.0
memory occupied  0.0
memory occupied  28.978365898132324
memory occupied  0.0
memory occupied  0.0
decoder out 48.0 torch.Size([4, 8192, 384]) 4
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  29625 MiB |  29915 MiB |  61352 MiB |  31726 MiB |
|       from large pool |  29571 MiB |  29861 MiB |  61133 MiB |  31561 MiB |
|       from small pool |     53 MiB |     54 MiB |    218 MiB |    165 MiB |
|---------------------------------------------------------------------------|
| Active memory         |  29625 MiB |  29915 MiB |  61352 MiB |  31726 MiB |
|       from large pool |  29571 MiB |  29861 MiB |  61133 MiB |  31561 MiB |
|       from small pool |     53 MiB |     54 MiB |    218 MiB |    165 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |  29606 MiB |  29896 MiB |  61319 MiB |  31713 MiB |
|       from large pool |  29552 MiB |  29842 MiB |  61100 MiB |  31548 MiB |
|       from small pool |     53 MiB |     54 MiB |    218 MiB |    165 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  30006 MiB |  30378 MiB |  31744 MiB |   1738 MiB |
|       from large pool |  29952 MiB |  30322 MiB |  31682 MiB |   1730 MiB |
|       from small pool |     54 MiB |     56 MiB |     62 MiB |      8 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory | 389539 KiB | 743586 KiB |  10122 MiB |   9741 MiB |
|       from large pool | 389200 KiB | 741256 KiB |   9913 MiB |   9533 MiB |
|       from small pool |    339 KiB |   4577 KiB |    208 MiB |    208 MiB |
|---------------------------------------------------------------------------|
| Allocations           |    1100    |    1107    |    1864    |     764    |
|       from large pool |     452    |     459    |     940    |     488    |
|       from small pool |     648    |     652    |     924    |     276    |
|---------------------------------------------------------------------------|
| Active allocs         |    1100    |    1107    |    1864    |     764    |
|       from large pool |     452    |     459    |     940    |     488    |
|       from small pool |     648    |     652    |     924    |     276    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     334    |     342    |     375    |      41    |
|       from large pool |     307    |     314    |     344    |      37    |
|       from small pool |      27    |      28    |      31    |       4    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     108    |     110    |     524    |     416    |
|       from large pool |     104    |     106    |     344    |     240    |
|       from small pool |       4    |      12    |     180    |     176    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
memory occupied  28.931241035461426
memory occupied  0.0
memory occupied  0.0
memory occupied  29.212491035461426
memory occupied  0.0
  0%|                                                                                                                                                             | 0/248 [00:00<?, ?it/s]Traceback (most recent call last):
  File "main.py", line 68, in <module>
    trainer.train(config)
  File "/raid/home/rizwank/courses/DLCV/Project/train.py", line 115, in train
    loss, loss_dict = self.train_step(batch)
  File "/raid/home/rizwank/courses/DLCV/Project/train.py", line 44, in train_step
    output = self.model.module(images)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/model.py", line 226, in forward
    x = self.swin_encoder_decoder(x)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/model.py", line 123, in forward
    decoder_out, _ = self.task_decoder[task_id][i](decoder_inp)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/model.py", line 32, in forward
    out = self.model(x, output_hidden_states=True)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 1011, in forward
    encoder_outputs = self.encoder(
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 836, in forward
    layer_outputs = layer_module(
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 756, in forward
    layer_outputs = layer_module(
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 687, in forward
    attention_outputs = self.attention(
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 562, in forward
    self_outputs = self.self(hidden_states, attention_mask, head_mask, output_attentions)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/rizwank/courses/DLCV/Project/transformers/src/transformers/models/swin/modeling_swin.py", line 477, in forward
    attention_scores = attention_scores / math.sqrt(self.attention_head_size)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 43.38 MiB is free. Process 2991625 has 436.00 MiB memory in use. Including non-PyTorch memory, this process has 31.26 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 462.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)